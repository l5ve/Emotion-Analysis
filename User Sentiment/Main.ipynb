{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956967341</th>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967666</th>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967696</th>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967789</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956968416</th>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918954</th>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919001</th>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919005</th>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919043</th>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919049</th>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment         author  \\\n",
       "tweet_id                                \n",
       "1956967341       empty     xoshayzers   \n",
       "1956967666     sadness      wannamama   \n",
       "1956967696     sadness      coolfunky   \n",
       "1956967789  enthusiasm    czareaquino   \n",
       "1956968416     neutral      xkilljoyx   \n",
       "...                ...            ...   \n",
       "1753918954     neutral  showMe_Heaven   \n",
       "1753919001        love       drapeaux   \n",
       "1753919005        love       JenniRox   \n",
       "1753919043   happiness       ipdaman1   \n",
       "1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                       status  \n",
       "tweet_id                                                       \n",
       "1956967341  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1956967666  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "1956967696                Funeral ceremony...gloomy friday...  \n",
       "1956967789               wants to hang out with friends SOON!  \n",
       "1956968416  @dannycastillo We want to trade with someone w...  \n",
       "...                                                       ...  \n",
       "1753918954                                   @JohnLloydTaylor  \n",
       "1753919001                     Happy Mothers Day  All my love  \n",
       "1753919005  Happy Mother's Day to all the mommies out ther...  \n",
       "1753919043  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "1753919049  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data\n",
    "data = pd.read_csv('data\\\\text_emotion.csv',index_col='tweet_id')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "data=data.drop('author',axis=1)\n",
    "#data=data.drop('tweet_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Shuvo\n",
      "[nltk_data]     Podder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Shuvo\n",
      "[nltk_data]     Podder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956967341</th>\n",
       "      <td>empty</td>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967666</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967696</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967789</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956968416</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo want trade someone houston ticke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918954</th>\n",
       "      <td>neutral</td>\n",
       "      <td>johnlloydtaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919001</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919005</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day mommy woman man long momma so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919043</th>\n",
       "      <td>happiness</td>\n",
       "      <td>niariley wassup beautiful follow peep new hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919049</th>\n",
       "      <td>love</td>\n",
       "      <td>mopedronin bullet train tokyo gf visiting japa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment                                             status\n",
       "tweet_id                                                                 \n",
       "1956967341       empty  tiffanylue know listenin bad habit earlier sta...\n",
       "1956967666     sadness              layin n bed headache ughh waitin call\n",
       "1956967696     sadness                     funeral ceremony gloomy friday\n",
       "1956967789  enthusiasm                              want hang friend soon\n",
       "1956968416     neutral  dannycastillo want trade someone houston ticke...\n",
       "...                ...                                                ...\n",
       "1753918954     neutral                                    johnlloydtaylor\n",
       "1753919001        love                              happy mother day love\n",
       "1753919005        love  happy mother day mommy woman man long momma so...\n",
       "1753919043   happiness  niariley wassup beautiful follow peep new hit ...\n",
       "1753919049        love  mopedronin bullet train tokyo gf visiting japa...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "lower_case = lambda x:\" \".join(x.lower() for x in x.split())\n",
    "data['status'] = data['status'].apply(lower_case)\n",
    "\n",
    "#remove punctuation,symbols\n",
    "data['status'] = data['status'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "#remove stopwords\n",
    "stop_word = stopwords.words('english')\n",
    "stop_words = lambda x:\" \".join(x for x in x.split() if x not in stop_word)\n",
    "data['status'] = data['status'].apply(stop_words)\n",
    "\n",
    "#lematisation \n",
    "ls = lambda x:\" \".join([Word(word).lemmatize() for word in x.split()])\n",
    "data['status'] = data['status'].apply(ls)\n",
    "\n",
    "#fixing repeatations\n",
    "def repeat(text):\n",
    "    pt=re.compile(r\"(.)\\1{2,}\")\n",
    "    return pt.sub(r\"\\1\\1\",text)\n",
    "rt=lambda x:\" \".join(repeat(x) for x in x.split())\n",
    "data['status'] = data['status'].apply(rt)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956967341</th>\n",
       "      <td>empty</td>\n",
       "      <td>know listenin bad habit earlier started freaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967666</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967696</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956967789</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956968416</th>\n",
       "      <td>neutral</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753918954</th>\n",
       "      <td>neutral</td>\n",
       "      <td>johnlloydtaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919001</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919005</th>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day mommy woman man long momma so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919043</th>\n",
       "      <td>happiness</td>\n",
       "      <td>niariley wassup beautiful follow peep new hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753919049</th>\n",
       "      <td>love</td>\n",
       "      <td>mopedronin bullet train tokyo gf visiting japa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentiment                                             status\n",
       "tweet_id                                                                 \n",
       "1956967341       empty  know listenin bad habit earlier started freaki...\n",
       "1956967666     sadness              layin n bed headache ughh waitin call\n",
       "1956967696     sadness                     funeral ceremony gloomy friday\n",
       "1956967789  enthusiasm                              want hang friend soon\n",
       "1956968416     neutral              want trade someone houston ticket one\n",
       "...                ...                                                ...\n",
       "1753918954     neutral                                    johnlloydtaylor\n",
       "1753919001        love                              happy mother day love\n",
       "1753919005        love  happy mother day mommy woman man long momma so...\n",
       "1753919043   happiness  niariley wassup beautiful follow peep new hit ...\n",
       "1753919049        love  mopedronin bullet train tokyo gf visiting japa...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq= pd.Series(' '.join(data['status']).split()).value_counts()[-10000:]\n",
    "#remove rarely words\n",
    "freq=list(freq.index)\n",
    "data['status'] = data['status'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data\\\\clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>know listenin bad habit earlier started freaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>johnlloydtaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day mommy woman man long momma so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>niariley wassup beautiful follow peep new hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>mopedronin bullet train tokyo gf visiting japa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                  status  \n",
       "0      know listenin bad habit earlier started freaki...  \n",
       "1                  layin n bed headache ughh waitin call  \n",
       "2                         funeral ceremony gloomy friday  \n",
       "3                                  want hang friend soon  \n",
       "4                  want trade someone houston ticket one  \n",
       "...                                                  ...  \n",
       "39995                                    johnlloydtaylor  \n",
       "39996                              happy mother day love  \n",
       "39997  happy mother day mommy woman man long momma so...  \n",
       "39998  niariley wassup beautiful follow peep new hit ...  \n",
       "39999  mopedronin bullet train tokyo gf visiting japa...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data\\\\clean_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sleep im thinking old friend want married damn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>charlene love miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>1753918900</td>\n",
       "      <td>happiness</td>\n",
       "      <td>succesfully following tayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>happy mother day mommy woman man long momma so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>niariley wassup beautiful follow peep new hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>mopedronin bullet train tokyo gf visiting japa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16930 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "6      1956968487     sadness   \n",
       "8      1956969035     sadness   \n",
       "...           ...         ...   \n",
       "39994  1753918900   happiness   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                  status  \n",
       "1                  layin n bed headache ughh waitin call  \n",
       "2                         funeral ceremony gloomy friday  \n",
       "3                                  want hang friend soon  \n",
       "6      sleep im thinking old friend want married damn...  \n",
       "8                                     charlene love miss  \n",
       "...                                                  ...  \n",
       "39994                        succesfully following tayla  \n",
       "39996                              happy mother day love  \n",
       "39997  happy mother day mommy woman man long momma so...  \n",
       "39998  niariley wassup beautiful follow peep new hit ...  \n",
       "39999  mopedronin bullet train tokyo gf visiting japa...  \n",
       "\n",
       "[16930 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with other emotion labels\n",
    "#data = data.drop(data[data.sentiment == 'love'].index)\n",
    "#data = data.drop(data[data.sentiment == 'boredom'].index)\n",
    "#data = data.drop(data[data.sentiment == 'fun'].index)\n",
    "#data = data.drop(data[data.sentiment == 'enthusiasm'].index)\n",
    "data = data.drop(data[data.sentiment == 'anger'].index)\n",
    "data = data.drop(data[data.sentiment == 'empty'].index)\n",
    "data = data.drop(data[data.sentiment == 'relief'].index)\n",
    "data = data.drop(data[data.sentiment == 'surprise'].index)\n",
    "data = data.drop(data[data.sentiment == 'hate'].index)\n",
    "data = data.drop(data[data.sentiment == 'neutral'].index)\n",
    "data = data.drop(data[data.sentiment == 'worry'].index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding output labels\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiment.values.astype('U'))\n",
    "\n",
    "#split data into train 90% and test 10%\n",
    "x_train,x_val,y_train,y_val = train_test_split(data.status.values.astype('U'),\n",
    "                                              y,stratify=y,random_state = 42,\n",
    "                                              test_size = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting TF-IDF parameters\n",
    "tfidf = TfidfVectorizer(max_features = 1000,analyzer ='word',ngram_range=(1,3))\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_val_tfidf =tfidf.fit_transform(x_val)\n",
    "\n",
    "# Extracting Count Vectors Parameters\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data['status'].values.astype('U'))\n",
    "x_train_count = count_vect.transform(x_train)\n",
    "x_val_count = count_vect.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5363260484347312\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_count,y_train)\n",
    "y_pred = nb.predict(x_val_count)\n",
    "#Evaluate\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(nb,open('data\\\\model.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = pickle.load(open('data\\\\model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness</td>\n",
       "      <td>you are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I jshd sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happiness</td>\n",
       "      <td>I am gshssj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment         song\n",
       "0     sadness         I am\n",
       "1   happiness      you are\n",
       "2     sadness    I jshd sd\n",
       "3  happiness   I am gshssj"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read songs sentiment\n",
    "song =pd.read_csv(\"data\\\\song_lyrics.csv\")\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion(status):\n",
    "    text = pd.DataFrame([status])\n",
    "    \n",
    "    # Doing some preprocessing on these text as done before\n",
    "    text[0] = text[0].str.replace('[^\\w\\s]',' ')\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    text[0] = text[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    from textblob import Word\n",
    "    text[0] = text[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    # Extracting Count Vectors feature from our text\n",
    "    text_count = count_vect.transform(text[0])\n",
    "    #Predicting the emotion of the tweet using our already trained linear SVM\n",
    "    result = model.predict(text_count)\n",
    "    #print(result)\n",
    "    #lbl_enc.transform(data.sentiment.values.astype('U'))\n",
    "    #print(lbl_enc.inverse_transform([result]))\n",
    "    emotions= lbl_enc.inverse_transform([result])\n",
    "    for e in emotions:\n",
    "        st=e\n",
    "    print(\"You seems %s today. Here is your recomended songs list: \" %st)\n",
    "    print(song.loc[song['sentiment']==st])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input Though text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am very happy today\n",
      "You seems happiness today. Here is your recomended songs list: \n",
      "   sentiment     song\n",
      "1  happiness  you are\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuvo Podder\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "str = input()\n",
    "emotion(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input Though Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something\n",
      "................................\n",
      "Text: I am very happy today. Lucky\n",
      "You seems happiness today. Here is your recomended songs list: \n",
      "   sentiment     song\n",
      "1  happiness  you are\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuvo Podder\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:289: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r=sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print('Say something')\n",
    "    audio=r.listen(source)   #audio_data = r.record(source, duration=5)\n",
    "    print(\"................................\")\n",
    "    \n",
    "try:\n",
    "    str=r.recognize_google(audio)\n",
    "    print(\"Text: \"+str);\n",
    "    emotion(str)\n",
    "    \n",
    "except:\n",
    "    print('error')\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
